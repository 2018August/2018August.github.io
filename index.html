<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content=""><meta name="keywords" content=""><meta name="author" content="August,undefined"><meta name="copyright" content="August"><title>Technologies come and technologies go, but insight is forever. | I Love AI</title><link rel="shortcut icon" href="/favicon.ico"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.min.css?version=1.5.3"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  localSearch: undefined
} </script></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="author-info"><div class="author-info__avatar text-center"><img src="http://p7l96nurm.bkt.clouddn.com/blog/180423/kC2iKEe0K1.jpg"></div><div class="author-info__name text-center">August</div><div class="author-info__description text-center"></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">2</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">2</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">1</span></a></div></div></div><nav class="https://i.loli.net/2018/04/23/5addf1ffb8e92.jpg" id="nav" style="background-image: url(https://i.loli.net/2018/04/23/5addf1ffb8e92.jpg)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">I Love AI</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="site-info"><div id="site-title">I Love AI</div><div id="site-sub-title">Technologies come and technologies go, but insight is forever.</div></div></nav><div id="content-outer"><div class="layout" id="content-inner"><div class="recent-post-item"><a class="article-title" href="/hello-world/">Hello World</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-04-23</time><div class="content"><p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>
</div><hr></div><div class="recent-post-item"><a class="article-title" href="/机器学习评估指标的前世今生/">机器学习评估指标的前世今生</a><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-04-22</time><span class="article-meta"><span class="article-meta__separator">|</span><i class="fa fa-inbox article-meta__icon" aria-hidden="true"></i><a class="article-meta__categories" href="/categories/machine-learning/">machine learning</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/机器学习/">机器学习</a><span class="article-meta__link">-</span><i class="fa fa-tag article-meta__icon" aria-hidden="true"></i><a class="article-meta__tags" href="/tags/评估指标/">评估指标</a></span><div class="content"><p>我们先来看一下sklearn中支持哪些机器学习的评估指标：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> SCORERS</span><br><span class="line">SCORERS</span><br></pre></td></tr></table></figure>
<blockquote>
<p>{‘accuracy’: make_scorer(accuracy_score),<br> ‘adjusted_rand_score’: make_scorer(adjusted_rand_score),<br> ‘average_precision’: make_scorer(average_precision_score, needs_threshold=True),<br> ‘f1’: make_scorer(f1_score),<br> ‘f1_macro’: make_scorer(f1_score, average=macro, pos_label=None),<br> ‘f1_micro’: make_scorer(f1_score, average=micro, pos_label=None),<br> ‘f1_samples’: make_scorer(f1_score, average=samples, pos_label=None),<br> ‘f1_weighted’: make_scorer(f1_score, average=weighted, pos_label=None),<br> ‘log_loss’: make_scorer(log_loss, greater_is_better=False, needs_proba=True),<br> ‘mean_absolute_error’: make_scorer(mean_absolute_error, greater_is_better=False),<br> ‘mean_squared_error’: make_scorer(mean_squared_error, greater_is_better=False),<br> ‘median_absolute_error’: make_scorer(median_absolute_error, greater_is_better=False),<br> ‘neg_log_loss’: make_scorer(log_loss, greater_is_better=False, needs_proba=True),<br> ‘neg_mean_absolute_error’: make_scorer(mean_absolute_error, greater_is_better=False),<br> ‘neg_mean_squared_error’: make_scorer(mean_squared_error, greater_is_better=False),<br> ‘neg_median_absolute_error’: make_scorer(median_absolute_error, greater_is_better=False),<br> ‘precision’: make_scorer(precision_score),<br> ‘precision_macro’: make_scorer(precision_score, average=macro, pos_label=None),<br> ‘precision_micro’: make_scorer(precision_score, average=micro, pos_label=None),<br> ‘precision_samples’: make_scorer(precision_score, average=samples, pos_label=None),<br> ‘precision_weighted’: make_scorer(precision_score, average=weighted, pos_label=None),<br> ‘r2’: make_scorer(r2_score),<br> ‘recall’: make_scorer(recall_score),<br> ‘recall_macro’: make_scorer(recall_score, average=macro, pos_label=None),<br> ‘recall_micro’: make_scorer(recall_score, average=micro, pos_label=None),<br> ‘recall_samples’: make_scorer(recall_score, average=samples, pos_label=None),<br> ‘recall_weighted’: make_scorer(recall_score, average=weighted, pos_label=None),<br> ‘roc_auc’: make_scorer(roc_auc_score, needs_threshold=True)}</p>
</blockquote>
<p>哇，好多，这么多指标，我们都要会用吗？实际上不是这样的，我们平时工作中只会使用一些比较常见的指标，并且根据这些常见的指标（注意不是一个指标！）综合评价我们的模型。下面我们就一一揭晓这些常见评估方法的神秘面纱！</p>
<h2 id="1-回归（Regression）算法指标大揭秘"><a href="#1-回归（Regression）算法指标大揭秘" class="headerlink" title="1. 回归（Regression）算法指标大揭秘"></a>1. 回归（Regression）算法指标大揭秘</h2><ul>
<li><h5 id="Mean-Absolute-Error-平均绝对误差"><a href="#Mean-Absolute-Error-平均绝对误差" class="headerlink" title="Mean Absolute Error 平均绝对误差"></a>Mean Absolute Error 平均绝对误差</h5></li>
<li><h5 id="Mean-Squared-Error-均方误差"><a href="#Mean-Squared-Error-均方误差" class="headerlink" title="Mean Squared Error 均方误差"></a>Mean Squared Error 均方误差</h5></li>
<li><h5 id="Root-Mean-Squared-Error：均方根误差"><a href="#Root-Mean-Squared-Error：均方根误差" class="headerlink" title="Root Mean Squared Error：均方根误差"></a>Root Mean Squared Error：均方根误差</h5></li>
<li><h5 id="Coefficient-of-determination-决定系数"><a href="#Coefficient-of-determination-决定系数" class="headerlink" title="Coefficient of determination 决定系数"></a>Coefficient of determination 决定系数</h5></li>
</ul>
<p>以下为一元变量和二元变量的线性回归示意图：</p>
<p><img src="http://p7l96nurm.bkt.clouddn.com/blog/180423/G85g8Id7mg.jpg?imageslim" width="60%"></p>
<p>怎样来衡量回归模型的好坏呢？</p>
<p>我们第一眼自然而然会想到采用残差（实际值与预测值差值）的均值来衡量，即：</p>
<script type="math/tex; mode=display">
{\rm residual}(y, \hat{y})=\frac{1}{m}\sum\limits_{i=1}^{n}(y_i-\hat{y}_i)</script><p><strong><em>问题 1：用残差的均值合理吗？</em></strong></p>
<p>当实际值分布在拟合曲线两侧时，对于不同样本而言$y_i-\hat{y}_i$ 有正有负，相互抵消，因此我们想到采用预测值和真实值之间的距离来衡量。</p>
<h4 id="1-1-平均绝对误差-MAE"><a href="#1-1-平均绝对误差-MAE" class="headerlink" title="1.1 平均绝对误差 MAE"></a>1.1 平均绝对误差 MAE</h4><p>平均绝对误差MAE（Mean Absolute Error）又被称为 $l1$ 范数损失（$l1-norm loss$）,</p>
<script type="math/tex; mode=display">
{\rm MAE}(y, \hat{y})=\frac{1}{m}\sum\limits_{i=1}^{n}|y_i-\hat{y}_i|</script><p><strong><em>问题 2：MAE有哪些不足？</em></strong></p>
<p>MAE虽能较好衡量回归模型的好坏，但是绝对值的存在导致函数不光滑，在某些点上不能求导，可以考虑将绝对值改为残差的平方，这就是均方误差。</p>
<h4 id="1-2-均方误差-MSE"><a href="#1-2-均方误差-MSE" class="headerlink" title="1.2 均方误差 MSE"></a>1.2 均方误差 MSE</h4><p>均方误差MSE（Mean  Squared Error）又被称为 $l2$ 范数损失（$l2-norm loss$）。</p>
<script type="math/tex; mode=display">
{\rm MSE}(y, \hat{y})=\frac{1}{m}\sum\limits_{i=1}^{m}(y_i-\hat{y}_i)^2</script><p><strong><em>问题 3： 还有没有比MSE更合理一些的指标？</em></strong></p>
<p>由于MSE与我们的目标变量的量纲不一致，为了保证量纲一致性，我们需要对MSE进行开方。</p>
<h4 id="1-3-均方根误差-RMSE"><a href="#1-3-均方根误差-RMSE" class="headerlink" title="1.3 均方根误差 RMSE"></a>1.3 均方根误差 RMSE</h4><script type="math/tex; mode=display">
{\rm RMSE}(y, \hat{y})=\sqrt {\frac{1}{m}\sum\limits_{i=1}^{m}(y_i-\hat{y}_i)^2}</script><p><strong><em>问题 4： RMSE有没有不足的地方？有没有规范化（无量纲化的指标）？</em></strong></p>
<p>上面的几种衡量标准的取值大小与具体的应用场景有关系，很难定义统一的规则来衡量模型的好坏。比如说利用机器学习算法预测上海的房价RMSE在2000元，我们是可以接受的，但是当四五线城市的房价RMSE为2000元，我们还可以接受吗？下面介绍的决定系数就是一个无量纲化的指标。</p>
<h4 id="1-4-决定系数-R-2"><a href="#1-4-决定系数-R-2" class="headerlink" title="1.4 决定系数 $R^2$"></a>1.4 决定系数 $R^2$</h4><p>变量之所以有价值，就是因为变量是变化的。什么意思呢？比如说一组因变量为[0, 0, 0, 0, 0]，显然该因变量的结果是一个常数0，我们也没有必要建模对该因变量进行预测。假如一组的因变量为[1, 3, 7, 10, 12]，该因变量是变化的，也就是有变异，因此需要通过建立回归模型进行预测。这里的变异可以理解为一组数据的方差不为0。</p>
<p>决定系数又称为 $R^2$ score，反应因变量的全部变异能通过回归关系被自变量解释的比例。</p>
<p>$\text{SST} = \sum \limits_i^m(y_i - \bar y)^2 \qquad \text{SST = total sum of squares}$</p>
<p>$\text{SSR} = \sum \limits_i^m(\hat y_i - \bar y)^2 \qquad \text{SSR = sum of due to regression}$</p>
<p>$\text{SSE} = \sum \limits_i^m(\hat y_i - y_i)^2  \qquad \text{SSE = sum of due to erros}$</p>
<p>$\text{SST = SSR + SSE}$</p>
<script type="math/tex; mode=display">
R^2(y,\hat{y})= \frac{\rm SSR}{\rm SST}</script><p>如果结果是0，就说明模型预测不能预测因变量。<br>如果结果是1。就说明是函数关系。<br>如果结果是0-1之间的数，就是我们模型的好坏程度。 </p>
<p>化简上面的公式 ,分子就变成了我们的均方误差MSE，下面分母就变成了方差:</p>
<script type="math/tex; mode=display">
R^2(y,\hat{y})=1 - \frac{\rm SSE}{\rm SST}=1-\frac{\sum\limits_{i=1}^{m}(y_i-\hat{y}_i)^2}{\sum\limits_{i=1}^{m}(y_i-\bar{y})^2}=1-\frac{\sum\limits_{i=1}^{m}(y_i-\hat{y}_i)^2/m}{\sum\limits_{i=1}^{m}(y_i-\bar{y})^2/m}  = 1 - \frac{\rm MSE(\hat y, y)}{\rm Var(y)}</script><p><strong><em>问题 5： 以上评估指标有没有缺陷，如果有，该怎样改进？</em></strong></p>
<p>以上的评估指标是基于误差的均值对进行评估的，均值对异常点（outliers）较敏感，如果样本中有一些异常值出现，会对以上指标的值有较大影响，即均值是非鲁棒的。 </p>
<h4 id="1-5-解决评估指标鲁棒性问题"><a href="#1-5-解决评估指标鲁棒性问题" class="headerlink" title="1.5 解决评估指标鲁棒性问题"></a>1.5 解决评估指标鲁棒性问题</h4><p>我们通常用一下两种方法解决评估指标的鲁棒性问题：</p>
<ul>
<li>剔除异常值</li>
</ul>
<p>设定一个相对误差 $\frac{|y_i-\hat{y_i}|}{y_i}$，当该值超过一定的阈值时，则认为其是一个异常点，剔除这个异常点，将异常点剔除之后。再计算平均误差来对模型进行评价。</p>
<ul>
<li>使用误差的分位数来代替，</li>
</ul>
<p>如利用中位数来代替平均数。例如 MAPE:</p>
<script type="math/tex; mode=display">
MAPE=median(|y_i-\hat{y_i}|/y_i)</script><p>MAPE是一个相对误差的中位数，当然也可以使用别的分位数。 </p>
<h2 id="2-分类（Classification）算法指标大揭秘"><a href="#2-分类（Classification）算法指标大揭秘" class="headerlink" title="2. 分类（Classification）算法指标大揭秘"></a>2. 分类（Classification）算法指标大揭秘</h2><ul>
<li><h5 id="精度-Accuracy"><a href="#精度-Accuracy" class="headerlink" title="精度 Accuracy"></a>精度 Accuracy</h5></li>
<li><h5 id="混淆矩阵-Confusion-Matrix"><a href="#混淆矩阵-Confusion-Matrix" class="headerlink" title="混淆矩阵 Confusion Matrix"></a>混淆矩阵 Confusion Matrix</h5></li>
<li><h5 id="准确率（查准率）-Precision"><a href="#准确率（查准率）-Precision" class="headerlink" title="准确率（查准率） Precision"></a>准确率（查准率） Precision</h5></li>
<li><h5 id="召回率（查全率）Recall"><a href="#召回率（查全率）Recall" class="headerlink" title="召回率（查全率）Recall"></a>召回率（查全率）Recall</h5></li>
<li><h5 id="F-beta-Score"><a href="#F-beta-Score" class="headerlink" title="$F_\beta$ Score"></a>$F_\beta$ Score</h5></li>
<li><h5 id="AUC-Area-Under-Curve"><a href="#AUC-Area-Under-Curve" class="headerlink" title="AUC Area Under Curve"></a>AUC Area Under Curve</h5></li>
<li><h5 id="KS-Kolmogorov-Smirnov"><a href="#KS-Kolmogorov-Smirnov" class="headerlink" title="KS Kolmogorov-Smirnov"></a>KS Kolmogorov-Smirnov</h5></li>
</ul>
<h4 id="2-1-精度-Acc"><a href="#2-1-精度-Acc" class="headerlink" title="2.1 精度 Acc"></a>2.1 精度 Acc</h4><p>预测正确的样本的占总样本的比例，取值范围为[0,1]，取值越大，模型预测能力越好。</p>
<script type="math/tex; mode=display">
Acc(y, \hat y)=\frac{1}{n}\sum\limits_{i=1}^{m}sign(\hat{y}_i,  y_i)</script><p>其中$sign(\hat y_i,  y_i) = \left\{  \begin{array} 1 \qquad  \hat y_i=y_i\ 0 \qquad \hat y_i \neq y_i\end{array} \right.$</p>
<p>精度评价指标对平等对待每个类别，即每一个样本判对 (0) 和判错 (1) 的代价都是一样的</p>
<p><strong><em>问题 6： 精度有什么缺陷？什么时候精度指标会失效？</em></strong></p>
<ul>
<li>对于有倾向性的问题，往往不能用精度指标来衡量。比如，判断空中的飞行物是导弹还是其他飞行物，很显然为了减少损失，我们更倾向于相信是导弹而采用相应的防护措施。此时判断为导弹实际上是其他飞行物与判断为其他飞行物实际上是导弹这两种情况的重要性是不一样的；</li>
<li>对于样本类别数量严重不均衡的情况，也不能用精度指标来衡量。比如银行客户样本中好客户990个，坏客户10个。如果一个模型直接把所有客户都判断为好客户，得到精度为99%，但这显然是没有意义的。</li>
</ul>
<p>对于以上两种情况，单纯根据Accuracy来衡量算法的优劣已经失效。这个时候就需要对目标变量的真实值和预测值做更深入的分析。</p>
<h4 id="2-2-混淆矩阵-Confusion-Matrix"><a href="#2-2-混淆矩阵-Confusion-Matrix" class="headerlink" title="2.2 混淆矩阵 Confusion Matrix"></a>2.2 混淆矩阵 Confusion Matrix</h4><p>混淆矩阵，在无监督学习中被称为匹配矩阵(matching matrix)，之所以叫混淆矩阵，是因为我们能够很 easy 从图表中看到分类器有没有将样本的类别给混淆了。矩阵每一列表示分类器预测值，每一行表示样本真实值。</p>
<p>混淆矩阵如下图所示：</p>
<p><img src="http://p7l96nurm.bkt.clouddn.com/blog/180423/lCLGGf9aEA.png?imageslim" alt="mark"></p>
<p>这里牵扯到三个方面：真实值，预测值，预测值和真实值之间的关系，其中任意两个方面都可以确定第三个。   </p>
<p>通常取预测值和真实值之间的关系、预测值对矩阵进行划分：</p>
<ul>
<li><p><strong>True positive (TP)</strong>  </p>
<p>真实值为Positive，预测正确（预测值为Positive）</p>
</li>
<li><p><strong>True negative (TN)</strong>  </p>
<p>真实值为Negative，预测正确（预测值为Negative）</p>
</li>
<li><p><strong>False positive (FP)</strong>  </p>
<p>真实值为Negative，预测错误（预测值为Positive），第一类错误， Type I error。</p>
</li>
<li><p><strong>False negative (FN)</strong>  </p>
<p>真实值为Positive，预测错误（预测值为 Negative），第二类错误， Type II error。 </p>
</li>
</ul>
<p>混淆矩阵的衍生指标：</p>
<p><img src="http://p7l96nurm.bkt.clouddn.com/blog/180423/8JAKkfi2ag.png" alt="mark"></p>
<p><img src="http://p7l96nurm.bkt.clouddn.com/blog/180423/4EJGG7k6fa.png?imageslim" alt="mark"></p>
<p><img src="http://p7l96nurm.bkt.clouddn.com/blog/180423/BbBi71cI6a.png?imageslim" alt="mark"></p>
<h4 id="2-3-准确率（查准率）-Precision"><a href="#2-3-准确率（查准率）-Precision" class="headerlink" title="2.3 准确率（查准率） Precision"></a>2.3 准确率（查准率） Precision</h4><p>Precision 是分类器预测的正样本中预测正确的比例，取值范围为[0,1]，取值越大，模型预测能力越好。</p>
<script type="math/tex; mode=display">
\text{P} = \frac{TP}{TP + FP}</script><h4 id="2-4-召回率（查全率）Recall"><a href="#2-4-召回率（查全率）Recall" class="headerlink" title="2.4 召回率（查全率）Recall"></a>2.4 召回率（查全率）Recall</h4><p>Recall 是分类器所预测正确的正样本占所有正样本的比例，取值范围为[0,1]，取值越大，模型预测能力越好。</p>
<script type="math/tex; mode=display">
\text{R} = \frac{TP}{TP + FN}</script><p>应用场景：</p>
<ol>
<li>地震的预测<br>对于地震的预测，我们希望的是Recall非常高，也就是说每次地震我们都希望预测出来。这个时候我们可以牺牲Precision。情愿发出1000次警报，把10次地震都预测正确了；也不要预测100次对了8次漏了两次。</li>
<li>嫌疑人定罪<br>基于不错怪一个好人的原则，对于嫌疑人的定罪我们希望是非常准确的。即使有时候放过了一些罪犯，但也是值得的。因此我们希望有较高的Precision值，可以合理地牺牲Recall。</li>
</ol>
<p><strong><em>问题 7： 某一家互联网金融公司风控部门的主要工作是利用机器模型抓取坏客户。互联网金融公司要扩大业务量，尽量多的吸引好客户，此时风控部门该怎样调整Recall和Precision？如果公司坏账扩大，公司缩紧业务，尽可能抓住更多的坏客户，此时风控部门该怎样调整Recall和Precision？</em></strong></p>
<p>如果互联网公司要扩大业务量，为了减少好客户的误抓率，保证吸引更多的好客户，风控部门就会提高阈值，从而提高模型的查准率Precision，同时，也会放进一部分坏客户，导致查全率Recall下降。如果公司要缩紧业务，尽可能抓住更多的坏客户，风控部门就会降低阈值，从而提高模型的查全率Recall，但是这样会导致一部分好客户误抓，从而降低模型的查准率 Precision。</p>
<p>根据以上几个案，我们知道随着阈值的变化Recall和Precision往往会向着反方向变化，这种规律很难满足我们的期望，即Recall和Precision同时增大。</p>
<p><strong><em>问题 8： 有没有什么方法权衡Recall和Precision 的矛盾？</em></strong></p>
<p>我们可以用一个指标来统一Recall和Precision的矛盾，即利用Recall和Precision的加权调和平均值作为衡量标准。</p>
<h4 id="2-5-F-beta-Score"><a href="#2-5-F-beta-Score" class="headerlink" title="2.5 $F_\beta$ Score"></a>2.5 $F_\beta$ Score</h4><p>Precision和Recall 是互相影响的，理想情况下肯定是做到两者都高，但是一般情况下Precision高、Recall 就低，Recall 高、Precision就低。为了均衡两个指标，我们可以采用Precision和Recall的加权调和平均（weighted harmonic mean）来衡量，即$F_\beta$ Score，公式如下：</p>
<script type="math/tex; mode=display">
F_{\beta}=(1+\beta^2)\times\frac{\text{P}\times\text{R}}{\beta^2\times\text{P}+\text{R}}</script><p>$\beta$ 表示权重，</p>
<p>$\begin{eqnarray<em>} F_{\beta}&amp; = &amp;\frac{(1+\beta^2)\times\text{P}\times\text{R}}{\beta^2\times\text{P}+\text{R}} \ &amp; = &amp; \frac {1}{\frac{\beta^2}{(1+\beta^2)\times R}+\frac{1}{(1+\beta^2)\times P}}\ &amp; = &amp; \frac {1}{\frac{1}{(1+\frac{1}{\beta^2})\times R}+\frac{1}{(1+\beta^2)\times P}}\end{eqnarray</em>} $</p>
<p>当$\beta \rightarrow 0 ： F_{\beta} \approx P$ ；当$\beta \rightarrow  \infty： F_{\beta} \approx R$。</p>
<p>通俗的语言就是：$\beta$ 越大，Recall的权重越大，$\beta$越小，Precision的权重越大。</p>
<p>随着如 $\beta=1$ 为$F_1$，此时Precision和Recall的权重相等，公式如下：</p>
<script type="math/tex; mode=display">
F_{\beta}=F_{1}=\frac{2\times\text{P}\times\text{R}}{\text{P}+\text{R}}</script><p>由于$F_\beta$ Score 无法直观反映数据的情况，同时业务含义相对较弱，实际工作用到的不多。</p>
<p><strong><em>问题 9： 根据以下混淆矩阵计算Recall, Precision，TPR，FPR？</em></strong></p>
<p><img src="http://p7l96nurm.bkt.clouddn.com/blog/180423/ehgB3h3GhA.png?imageslim" width="60%"></p>
<script type="math/tex; mode=display">
\text{Recall} = \text{TPR} = \frac{TP}{TP + FN} = \frac{7448}{7448 + 7278} = 0.50577 \\
\text{Precision} = \frac{TP}{TP + FP} = \frac{7448}{7448 + 5187} = 0.5895 \\
\text{FPR} = \frac{FP}{FP + TN} = \frac{5187}{5187 + 58105} = 0.1136</script><p><strong><em>问题 10： 有没有办法观察模型好坏随阈值的变化趋势呢（提示：利用TPR, FPR两个指标）？</em></strong></p>
<p>有，ROC（Receiver Operating Characteristic）曲线</p>
<p><strong><em>问题 11： lr模型输出的是概率，需要设置阈值才能得到好坏客户，从而得到混淆矩阵，有没有一种指标不依赖于阈值？</em></strong></p>
<p>有，AUC</p>
<h4 id="2-6-ROC-和-AUC"><a href="#2-6-ROC-和-AUC" class="headerlink" title="2.6 ROC 和 AUC"></a>2.6 ROC 和 AUC</h4><p>AUC是一种模型分类指标，且仅仅是二分类模型的评价指标。AUC是Area Under Curve的简称，那么Curve就是ROC（Receiver Operating Characteristic），翻译为”接受者操作特性曲线”。也就是说ROC是一条曲线，AUC是一个面积值。</p>
<h5 id="2-6-1-ROC"><a href="#2-6-1-ROC" class="headerlink" title="2.6.1 ROC"></a>2.6.1 ROC</h5><p>ROC曲线为 FPR 与 TPR 之间的关系曲线，这个组合以 FPR 对 TPR，即是以代价 (costs) 对收益 (benefits)，显然收益越高，代价越低，模型的性能就越好。</p>
<ul>
<li><p>x 轴为假阳性率（FPR）：在所有的负样本中，分类器预测错误的比例</p>
<script type="math/tex; mode=display">FPR = \frac {FP}{FP+TN}</script></li>
<li><p>y 轴为真阳性率（TPR）：在所有的正样本中，分类器预测正确的比例（等于Recall）</p>
<script type="math/tex; mode=display">TPR = \frac {TP}{TP+FN}</script></li>
</ul>
<p>为了更好地理解ROC曲线，我们使用具体的实例来说明：</p>
<p>如在医学诊断的主要任务是尽量把生病的人群都找出来，也就是TPR越高越好。而尽量降低没病误诊为有病的人数，也就是FPR越低越好。</p>
<p>不难发现，这两个指标之间是相互制约的。如果某个医生对于有病的症状比较敏感，稍微的小症状都判断为有病，那么他的TPR应该会很高，但是FPR也就相应地变高。最极端的情况下，他把所有的样本都看做有病，那么TPR达到1，FPR也为1。</p>
<p>我们以FPR为横轴，TPR为纵轴，得到如下ROC空间。</p>
<p><img src="http://p7l96nurm.bkt.clouddn.com/blog/180423/l5mmIKL6ba.png?imageslim" width="60%"></p>
<p>我们可以看出，左上角的点(TPR=1，FPR=0)，为完美分类，也就是这个医生医术高明，诊断全对。点A(TPR&gt;FPR),医生A的判断大体是正确的。中线上的点B(TPR=FPR),也就是医生B全都是蒙的，蒙对一半，蒙错一半；下半平面的点C(TPR&lt;FPR)，这个医生说你有病，那么你很可能没有病，医生C的话我们要反着听，为真庸医。上图中一个阈值，得到一个点。现在我们需要一个独立于阈值的评价指标来衡量这个医生的医术如何，也就是遍历所有的阈值,得到 ROC 曲线。</p>
<p>假设下图是某医生的诊断统计图，为未得病人群（上图）和得病人群（下图）的模型输出概率分布图（横坐标表示模型输出概率，纵坐标表示概率对应的人群的数量），显然未得病人群的概率值普遍低于得病人群的输出概率值（即正常人诊断出疾病的概率小于得病人群诊断出疾病的概率）。</p>
<p>竖线代表阈值。显然，图中给出了某个阈值对应的混淆矩阵，通过改变不同的阈值$1.0 \rightarrow 0$，得到一系列的混淆矩阵，进而得到一系列的TPR和FPR，绘制出ROC曲线。</p>
<p>阈值为1时，不管你什么症状，医生均未诊断出疾病（预测值都为N），此时 $FPR=TPR=0$，位于左下。阈值为 0 时，不管你什么症状，医生都诊断结果都是得病（预测值都为P），此时 $FPR=TPR=1$，位于右上。</p>
<p><img src="http://p7l96nurm.bkt.clouddn.com/blog/180423/flFjjcDeIh.png?imageslim" alt="mark"></p>
<p><strong><em>问题 12：如下，是三个模型对于 ROC 曲线，请按照模型性能好坏对齐进行排序</em></strong></p>
<p><img src="http://p7l96nurm.bkt.clouddn.com/blog/180423/LAj1fjaIIC.png" width="60%"></p>
<p>由ROC曲线距离左上角越近分类器效果越好，我们可以知道分类器 4 效果最好， 分类器 1 效果最差。那么怎样判断分类器 2 和分类器 3 呢？我们引入了下面要讲的 AUC。</p>
<h5 id="2-6-2-AUC"><a href="#2-6-2-AUC" class="headerlink" title="2.6.2 AUC"></a>2.6.2 AUC</h5><p><strong>AUC定义：</strong></p>
<p>AUC 值为 ROC 曲线所覆盖的区域面积，显然，AUC越大，分类器分类效果越好。</p>
<p>AUC = 1，是完美分类器。</p>
<p>0.5 &lt; AUC &lt; 1，优于随机猜测。有预测价值。</p>
<p>AUC = 0.5，跟随机猜测一样（例：丢铜板），没有预测价值。</p>
<p>AUC &lt; 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。</p>
<p>注：对于AUC小于 0.5 的模型，我们可以考虑取反（模型预测为positive，那我们就取negtive），这样就可以保证模型的性能不可能比随机猜测差。</p>
<p>以下为ROC曲线和AUC值的实例：</p>
<p><img src="http://p7l96nurm.bkt.clouddn.com/blog/180423/EjHhCaim0B.png?imageslim" width="70%"></p>
<p><strong>AUC的物理意义</strong></p>
<p>AUC的物理意义正样本的预测结果大于负样本的预测结果的概率。所以AUC反应的是分类器对样本的排序能力。  </p>
<p>另外值得注意的是，AUC对样本类别是否均衡并不敏感，这也是不均衡样本通常用AUC评价分类器性能的一个原因。</p>
<p>下面从一个小例子解释AUC的含义：小明一家四口，小明5岁，姐姐10岁，爸爸35岁，妈妈33岁建立一个逻辑回归分类器，来预测小明家人为成年人概率，假设分类器已经对小明的家人做过预测，得到每个人为成人的概率。</p>
<ol>
<li>AUC更多的是关注对计算概率的排序，关注的是概率值的相对大小，与阈值和概率值的绝对大小没有关系</li>
</ol>
<p>例子中并不关注小明是不是成人，而关注的是，预测为成人的概率的排序。</p>
<p><strong><em>问题 13：以下为三种模型的输出结果，求三种模型的 AUC。</em></strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>小明</th>
<th>姐姐</th>
<th>妈妈</th>
<th>爸爸</th>
</tr>
</thead>
<tbody>
<tr>
<td>a</td>
<td>0.12</td>
<td>0.35</td>
<td>0.76</td>
<td>0.85</td>
</tr>
<tr>
<td>b</td>
<td>0.12</td>
<td>0.35</td>
<td>0.44</td>
<td>0.49</td>
</tr>
<tr>
<td>c</td>
<td>0.52</td>
<td>0.65</td>
<td>0.76</td>
<td>0.85</td>
</tr>
</tbody>
</table>
</div>
<p>AUC只与概率的相对大小（概率排序）有关，和绝对大小没关系。由于三个模型概率排序的前两位都是未成年人（小明，姐姐），后两位都是成年人（妈妈，爸爸），因此三个模型的AUC都等于1。</p>
<ol>
<li><p>AUC只关注正负样本之间的排序，并不关心正样本内部，或者负样本内部的排序。这也体现了AUC的本质：任意个正样本的概率都大于负样本的概率的能力  </p>
<p>例子中AUC只需要保证（小明和姐姐）（爸爸和妈妈），小明和姐姐在前2个排序，爸爸和妈妈在后2个排序，而不会考虑小明和姐姐谁在前，或者爸爸和妈妈谁在前。</p>
</li>
</ol>
<p><strong><em>问题 14：以下已经对分类器输出概率从小到大进行了排列，哪些情况的AUC等于1， 情况的AUC为0（其中背景色表示True value，红色表示成年人，蓝色表示未成年人）。</em></strong></p>
<p><img src="http://p7l96nurm.bkt.clouddn.com/blog/180423/dbJd1gb90j.png?imageslim" width="70%"></p>
<p>D 模型, E模型和F模型的AUC值为1，C 模型的AUC值为0（爸妈为成年人的概率小于小明和姐姐，显然这个模型预测反了）。</p>
<p><strong>AUC的计算：</strong></p>
<ul>
<li><p>法1：AUC 为 ROC 曲线下的面积，那我们直接计算面积可得。面积为一个个小的梯形面积（曲线）之和。计算的精度与阈值的精度有关。</p>
</li>
<li><p>法2：根据AUC的物理意义，我们计算正样本预测结果大于负样本预测结果的概率。取 $n_1<em>n_0$($n_1$ 为正样本数，$n_0$ 为负样本数)个二元组，比较 score（预测结果），最后得到 AUC。时间复杂度为 O(N</em>M)。</p>
</li>
</ul>
<p><strong><em>问题 15：为什么说 ROC 和AUC都能应用于非均衡的分类问题？</em></strong></p>
<p>ROC曲线只与横坐标 (FPR) 和 纵坐标 (TPR) 有关系，我们知道：</p>
<script type="math/tex; mode=display">
FPR = \frac {FP}{FP+TN}  \\
TPR = \frac {TP}{TP+FN}</script><p>以及混淆矩阵：</p>
<p><img src="http://p7l96nurm.bkt.clouddn.com/blog/180423/lCLGGf9aEA.png?imageslim" width="80%"></p>
<p>我们可以发现TPR只是正样本中（第一行）预测正确的概率，在正样本内部进行，并没有牵扯到负样本。而FPR只是负样本中（第二行）预测错误的概率，在负样本内部进行，并没有牵扯到正样本。TPR和FPR的计算并没有涉及正负样本的互动（也就是没有跨行）。和正负样本的比例没有关系。因此 ROC 的值与实际的正负样本比例无关，因此既可以用于均衡问题，也可以用于非均衡问题。而 AUC 的几何意义为ROC曲线下的面积，因此也和实际的正负样本比例无关。</p>
<h4 id="2-7-KS-Kolmogorov-Smirnov"><a href="#2-7-KS-Kolmogorov-Smirnov" class="headerlink" title="2.7 KS Kolmogorov-Smirnov"></a>2.7 KS Kolmogorov-Smirnov</h4><p>KS值是在模型中用于区分预测正负样本分隔程度的评价指标，一般应用于金融风控领域。与ROC曲线相似，ROC是以FPR作为横坐标，TPR作为纵坐标，通过改变不同阈值，从而得到ROC曲线。而在KS曲线中，则是以阈值作为横坐标，以FPR和TPR作为纵坐标，ks曲线则为TPR-FPR，ks曲线的最大值通常为ks值。</p>
<p>为什么这样求KS值呢？我们知道，当阈值减小时，TPR和FPR会同时减小，当阈值增大时，TPR和FPR会同时增大。而在实际工程中，我们希望TPR更大一些，FPR更小一些，即TPR-FPR越大越好，即ks值越大越好。</p>
<p>KS值的取值范围是[0，1]。通常来说，值越大，模型区分正负样本的能力越强（一般0.3以上，说明模型的效果比较好）。</p>
<p>以下为KS曲线的实例 ：</p>
<p><img src="http://p7l96nurm.bkt.clouddn.com/blog/180423/9KJ8iJE9jF.png" width="70%"></p>
<h2 id="3-评估指标和代价函数是一家人吗？"><a href="#3-评估指标和代价函数是一家人吗？" class="headerlink" title="3. 评估指标和代价函数是一家人吗？"></a>3. 评估指标和代价函数是一家人吗？</h2><p>代价函数：$f(\theta, y)$，又称Cost function，loss function objective function。一般用在训练过程中，用来定义预测值和真实值之间的距离（也就是衡量模型在训练集上的性能），作为模型调整参数的反馈。代价函数越小，模型性能越好。</p>
<p>评判指标：$f(\hat y, y)$，一般用于训练和测试过程中，用于评估模型好坏。评判指标越大（或越小），模型越好。</p>
<p>本质上代价函数和评判指标都是一家人，只他们的应用场景不同，分工不同。代价函数是用来优化模型参数的，评价指标是用来评判模型好坏的。</p>
<p>作为评判指标所具备的条件：</p>
<ol>
<li>直观，可以理解</li>
</ol>
<p>……</p>
<p>作为代价函数所具备的条件：</p>
<ol>
<li>函数光滑且可导：可用梯度下降求解极值</li>
<li>函数为凸函数：可用梯度下降求解最优解</li>
</ol>
<p>……</p>
<p>例如我们经常使用的分类器评判指标 AUC 就不能直接被优化，因此我们常采用交叉熵来代替 AUC 进行优化。 一般情况下，交叉熵越小，AUC 就会越大。</p>
<h2 id="4-补充小知识点：micro还是macro？"><a href="#4-补充小知识点：micro还是macro？" class="headerlink" title="4. 补充小知识点：micro还是macro？"></a>4. 补充小知识点：micro还是macro？</h2><p>假如我们有n个二分类混淆矩阵，怎样综合评价我们的模型呢？我们通常有两种方式一种叫macro，一种叫micro。</p>
<h4 id="4-1-macro方法"><a href="#4-1-macro方法" class="headerlink" title="4.1 macro方法"></a>4.1 macro方法</h4><ol>
<li><p>计算出各混淆矩阵的Recall，Precision，记为$(P_1, R_1)，(P_2，R_2)，\cdots，(P_n，R_n)$：</p>
<script type="math/tex; mode=display">
P_i =  \frac{TP_i}{TP_i + FP_i}\\
R_i =  \frac{TP_i}{TP_i + FN_i}\\</script></li>
<li><p>对各个混淆矩阵的Recall，Precision求平均，然后再根据求得的Recall，Precision计算F1。</p>
</li>
</ol>
<script type="math/tex; mode=display">
P_{macro} = \frac1n\sum\limits_{i=1}^n P_i \\
R_{macro} = \frac1n\sum\limits_{i=1}^n R_i \\
F1_{macro} = \frac{2\times P_{macro} \times R_{macro}}{ P_{macro} + R_{macro}}</script><h4 id="4-2-micro方法"><a href="#4-2-micro方法" class="headerlink" title="4.2 micro方法"></a>4.2 micro方法</h4><ol>
<li>将各混淆矩阵对应的元素进行平均，得到平均混淆矩阵：</li>
</ol>
<script type="math/tex; mode=display">
\overline {TP} = \frac1n\sum\limits_{i=1}^n (TP)_i \\
\overline {TN} = \frac1n\sum\limits_{i=1}^n (TN)_i \\
\overline {FP} = \frac1n\sum\limits_{i=1}^n (FP)_i \\
\overline {FN} = \frac1n\sum\limits_{i=1}^n (FN)_i \\</script><ol>
<li>再基于平均混淆矩阵计算Recall，Precision，然后再根据求得的Recall，Precision计算F1：</li>
</ol>
<script type="math/tex; mode=display">
{P_{micro}} = \frac{\overline {TP}}{\overline{TP} + \overline{FP}} \\
{R_{micro}} = \frac{\overline {TP}}{\overline{TP} + \overline{FN}} \\
F1_{micro} = \frac{2\times P_{micro} \times R_{micro}}{ P_{micro} + R_{micro}}</script><p>参考文献：</p>
<p>ROC 和 AUC 介绍以及如何计算AUC <a href="http://alexkong.net/2013/06/introduction-to-auc-and-roc/" target="_blank" rel="noopener">http://alexkong.net/2013/06/introduction-to-auc-and-roc/</a></p>
<p>混淆矩阵 维基百科 <a href="https://en.wikipedia.org/wiki/Confusion_matrix" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Confusion_matrix</a></p>
<p>ROC曲线与AUC <a href="https://blog.csdn.net/ice110956/article/details/20288239" target="_blank" rel="noopener">https://blog.csdn.net/ice110956/article/details/20288239</a></p>
</div><hr></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2013 - 2018 By August</div><div class="framework-info"><span>驱动 - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv"><i class="fa fa-user"></i><span id="busuanzi_value_site_uv"></span><span></span></span><span class="footer-separator">|</span><span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i><span id="busuanzi_value_site_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="/js/third-party/anime.min.js"></script><script src="/js/third-party/jquery.min.js"></script><script src="/js/third-party/jquery.fancybox.min.js"></script><script src="/js/third-party/velocity.min.js"></script><script src="/js/third-party/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.5.3"></script><script src="/js/fancybox.js?version=1.5.3"></script><script src="/js/sidebar.js?version=1.5.3"></script><script src="/js/copy.js?version=1.5.3"></script><script src="/js/fireworks.js?version=1.5.3"></script><script src="/js/transition.js?version=1.5.3"></script><script src="/js/scroll.js?version=1.5.3"></script><script src="/js/head.js?version=1.5.3"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.bootcss.com/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>